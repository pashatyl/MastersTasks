{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "TEST_SIZE = 0.2\n",
    "N = 5\n",
    "data = np.array(boston['data'])\n",
    "target = np.array(boston['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  5, 10,  2,  9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pierson(x, y):\n",
    "    return np.corrcoef(x, y)[0][1]\n",
    "\n",
    "\n",
    "def filter(features, lables, n: int = 5):\n",
    "    return np.argsort(list(map(lambda x: np.abs(pierson(x, lables)), features.T)))[-1:-n - 1:-1]\n",
    "\n",
    "\n",
    "filter(data, target, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 7, 11, 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greedy_forward_selection(data, lables, metric, n: int = 5):\n",
    "    top = []\n",
    "    features = set(range(data.shape[1]))\n",
    "    for _ in range(n):\n",
    "        res = [(f, metric(data[:, top + [f]], lables)) for f in features]\n",
    "        best = min(res, key=lambda x: x[1])[0]\n",
    "        top.append(best)\n",
    "        features.remove(best)\n",
    "    return top\n",
    "\n",
    "\n",
    "def greedy_backward_selection(data, lables, metric, n: int = 5):\n",
    "    top = set(range(data.shape[1]))\n",
    "    for _ in range(data.shape[1] - n):\n",
    "        res = [(f, metric(data[:, list(top - {f})], lables)) for f in top]\n",
    "        best = min(res, key=lambda x: x[1])[0]\n",
    "        top.remove(best)\n",
    "    return list(top)\n",
    "\n",
    "\n",
    "def linear_regression_metric(features, lables):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=TEST_SIZE, random_state=0)\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    return mean_squared_error(reg.predict(X_test), y_test)\n",
    "\n",
    "\n",
    "greedy_forward_selection(data, target, linear_regression_metric, N)\n",
    "greedy_backward_selection(data, target, linear_regression_metric, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вычисления параметра регуляризации переберем их в диапазоне 0-10(получен империческим путем), а параметр к выберем близким к нулю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 1, 6, 9, 11]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lasso_selection(features, lables, k: float = 1e-4, n: int = 5, step: float = 0.001):\n",
    "    alpha = None\n",
    "    min_mse = np.inf\n",
    "\n",
    "    for _alpha in np.arange(step, 10, step):\n",
    "        lasso = linear_model.Lasso(alpha=_alpha)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=TEST_SIZE, random_state=0)\n",
    "        lasso.fit(X_train, y_train)\n",
    "        cur_selected_features = np.abs(lasso.coef_) > k\n",
    "        selected_count = np.sum(cur_selected_features)\n",
    "        if selected_count > n or selected_count == 0:\n",
    "            continue\n",
    "        mse = mean_squared_error(lasso.predict(X_test), y_test)\n",
    "        if mse <= min_mse:\n",
    "            min_mse = mse\n",
    "            alpha = _alpha\n",
    "\n",
    "    if alpha is None:\n",
    "        raise Exception(f'Optimal featurese not found. Check k={k} n={n} step={step}')\n",
    "\n",
    "    lasso = linear_model.Lasso(alpha=alpha)\n",
    "    lasso.fit(features, lables)\n",
    "    return list(np.argsort(np.abs(lasso.coef_))[-1:-n - 1:-1])\n",
    "\n",
    "lasso_selection(data, target, k=1e-4, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
